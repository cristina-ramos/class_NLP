{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear_models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1aVn5hpGnUa7HP7U-qTyaur938gt44hVE",
      "authorship_tag": "ABX9TyOrU5tjF6ulYN0wkoq8JA7j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cristina-ramos/class_NLP/blob/main/Assignments/linear_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOYUyayq-vWU"
      },
      "source": [
        "> Retrieving the dataset, untar-ing the file and importing API's"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC2r7XttfJ1s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2ceef8f-f876-44d3-e702-327cdc451cd4"
      },
      "source": [
        "!wget 'http://www.cs.cornell.edu/people/pabo/movie-review-data/'\n",
        "!tar -xf scale_data.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-05 03:57:44--  http://www.cs.cornell.edu/people/pabo/movie-review-data/\n",
            "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 52.201.128.190\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|52.201.128.190|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘index.html.2’\n",
            "\n",
            "\rindex.html.2            [<=>                 ]       0  --.-KB/s               \rindex.html.2            [ <=>                ]   7.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-11-05 03:57:44 (139 MB/s) - ‘index.html.2’ saved [7176]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0wsTAIekEcx"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import string\n",
        "from sklearn import datasets, linear_model, metrics\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn import svm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, max_error\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce0wvph6-uQ1"
      },
      "source": [
        "> Creating a single dataset for classification from the IDs. I'm using Pandas I know that's not your favorite oops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moTGTGnV0X26"
      },
      "source": [
        "entries = glob.glob('/content/scaledata/*')\n",
        "entries.sort()\n",
        "\n",
        "ratings = []\n",
        "subject = []\n",
        "labels = []\n",
        "id = []\n",
        "\n",
        "for entry in entries:\n",
        "  set_of_entries = glob.glob(entry+'/*')\n",
        "  set_of_entries.sort()\n",
        "  for file in set_of_entries:\n",
        "    if 'id' in file:\n",
        "      id_list = open(file, 'r').read().split('\\n')\n",
        "      id_list.pop()\n",
        "    elif 'rating' in file:\n",
        "      ratings_list = open(file, 'r').read().split('\\n')\n",
        "      ratings_list.pop()\n",
        "    elif 'subj' in file:\n",
        "      subject_list = open(file, 'r').read().split('\\n')\n",
        "      subject_list.pop()\n",
        "    elif '3class' in file:\n",
        "      label_list = open(file, 'r').read().split('\\n')\n",
        "      label_list.pop()\n",
        "  id.extend(id_list)\n",
        "  ratings.extend(ratings_list)\n",
        "  subject.extend(subject_list)\n",
        "  labels.extend(label_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xmv6-8DaC6D_"
      },
      "source": [
        "data = pd.DataFrame()\n",
        "data['ratings'] = ratings\n",
        "data['subject'] = subject\n",
        "data['labels'] = labels\n",
        "data['id'] = id\n",
        "# print(data['ratings'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO2AAsMoF4Lm"
      },
      "source": [
        "> Next: splitting the datasets into train and test sets using sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6siYZ19KDOf-"
      },
      "source": [
        "train, test = train_test_split(data, test_size=0.2, random_state=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoeDIvPUGhzi"
      },
      "source": [
        "> Using CountVectorizer to generate feats from subject and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPg2ytCcGhDa"
      },
      "source": [
        "vect = CountVectorizer()\n",
        "X_train = vect.fit_transform(train['subject']).toarray()\n",
        "y_train = train['labels'].to_list()\n",
        "X_test = vect.transform(test['subject']).toarray()\n",
        "y_test = test['labels'].to_list()\n",
        "ystr_train = train['ratings'].to_list()\n",
        "yf_train = [float(i) for i in ystr_train]\n",
        "ystr_test = test['ratings'].to_list()\n",
        "yf_test = [float(i) for i in ystr_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTjyof5_rDqD"
      },
      "source": [
        "> Using sklearn's SGD Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTcH4WMzF_0U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c59ef61a-2ea1-4782-ab72-3f685af83207"
      },
      "source": [
        "reg = SGDRegressor(max_iter=100)\n",
        "reg.fit(X_train, yf_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
              "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
              "             learning_rate='invscaling', loss='squared_loss', max_iter=100,\n",
              "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=None,\n",
              "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
              "             warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAJOHRk6Hgg4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84e6074a-6f14-4af2-b050-e125b1023765"
      },
      "source": [
        "predict = reg.predict(X_test)\n",
        "errors = max_error(yf_test, predict)\n",
        "print(errors)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "84049408797.2691\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7PcGDeFzOKo"
      },
      "source": [
        "> Now for the SGD Classifier: I had to keep lowering the max iteration because it was taking up to 30 minutes at one point just to run block 41...not sure if that's just because of the size or something I'm doing wrong on my end"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQYM7nttH1vy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "743470ec-917c-47d1-de3f-76e4c08852ce"
      },
      "source": [
        "clf = SGDClassifier(loss=\"log\", penalty=\"l1\", max_iter=50)\n",
        "clf.fit(X_train, y_train)\n",
        "#this takes a lot longer than the l2 reg, I tried using sparsify() since it's recommended to make it easier to process L1 regularization but I didn't have much luck"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=50,\n",
              "              n_iter_no_change=5, n_jobs=None, penalty='l1', power_t=0.5,\n",
              "              random_state=None, shuffle=True, tol=0.001,\n",
              "              validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xD1js4fI2rA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "438197ab-4074-47f4-e022-69c293980c6e"
      },
      "source": [
        "#performance of the classifier with L1 regularization:\n",
        "clf_predict = clf.predict(X_test)\n",
        "print(\"Performance of Classifier with L1 is: \\n\" + metrics.classification_report(y_test, clf_predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performance of Classifier with L1 is: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.66      0.62       230\n",
            "           1       0.59      0.55      0.57       373\n",
            "           2       0.76      0.75      0.75       399\n",
            "\n",
            "    accuracy                           0.65      1002\n",
            "   macro avg       0.64      0.65      0.65      1002\n",
            "weighted avg       0.65      0.65      0.65      1002\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgZ7KCuVKhHx"
      },
      "source": [
        "# clf.n_iter_\n",
        "#just checking out of curiosity from the discussion in class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwwoJ6rfzhXF"
      },
      "source": [
        "> Performance of the Classifier on the test dataset with L2 regularization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3U2C1s3zlhu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97031acb-2e68-449e-a2c4-999163d0e431"
      },
      "source": [
        "clf = SGDClassifier(loss=\"log\", penalty=\"l2\", max_iter=50)\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"Performance of Classifier with L2: \\n\" + metrics.classification_report(y_test, clf.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performance of Classifier with L2: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.60      0.63       230\n",
            "           1       0.61      0.58      0.60       373\n",
            "           2       0.72      0.78      0.75       399\n",
            "\n",
            "    accuracy                           0.67      1002\n",
            "   macro avg       0.66      0.66      0.66      1002\n",
            "weighted avg       0.66      0.67      0.66      1002\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZPmxeGi96Sj"
      },
      "source": [
        "> L2 outperforms L1 which had a 0.45 accuracy score (or at least that was the original score when I first ran the code, again not too sure why the scores keep changing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvMq9E_N93Qf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67ea3fe4-b7cd-4735-9ecd-67db6578eecc"
      },
      "source": [
        "# clf_l2.n_iter_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRDv8eW8WnwB"
      },
      "source": [
        "> Evaluation scores through sklearn's cross validation cross_val_score function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LsHXFbaK3C-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8afd599b-7b21-477d-fb04-16da996a5b4f"
      },
      "source": [
        "parameters = [0.0001, 0.001, 0.015, 0.05]\n",
        "\n",
        "for k in parameters:\n",
        "  clf = SGDClassifier(loss=\"log\", max_iter=100, alpha=k)\n",
        "  scores = cross_val_score(clf, X_train, y_train, cv=None)\n",
        "  print(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.64669164 0.61423221 0.67790262 0.64918851 0.6225    ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.6454432  0.63545568 0.67041199 0.64419476 0.625     ]\n",
            "[0.65418227 0.64918851 0.66042447 0.66292135 0.63625   ]\n",
            "[0.65667915 0.62796504 0.68289638 0.65667915 0.63625   ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp_HbOVop0k-"
      },
      "source": [
        "> Using different loss function: perceptron. This performed about the same as the other functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWz90cfSp3_9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb856e6c-d388-4f6b-a7db-2d2ef36585f9"
      },
      "source": [
        "ptn = SGDClassifier(loss=\"perceptron\", max_iter=50)\n",
        "ptn.fit(X_train, y_train)\n",
        "print(\"Perceptron Classifier Report: \\n\" + metrics.classification_report(y_test, ptn.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perceptron Classifier Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.69      0.65       230\n",
            "           1       0.62      0.58      0.60       373\n",
            "           2       0.76      0.75      0.76       399\n",
            "\n",
            "    accuracy                           0.67      1002\n",
            "   macro avg       0.66      0.67      0.67      1002\n",
            "weighted avg       0.67      0.67      0.67      1002\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeYbzwsEtd1D"
      },
      "source": [
        "> What kind of multi-class strategy does SGDClassifier use?\n",
        "  \n",
        "  SGDClassifier uses a multinomial log regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFoekbwCzHm2"
      },
      "source": [
        "Hyperplane:"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}